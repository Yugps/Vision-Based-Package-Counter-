{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DJFJg3Ymhn-",
        "outputId": "ec61f388-3258-4b01-b34f-832539ba3350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.27-py3-none-any.whl (779 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/779.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m174.1/779.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.27\n"
          ]
        }
      ],
      "source": [
        "! pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO # Downloading the model\n",
        "\n",
        "model=YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Z2eK2rmuEB",
        "outputId": "9a313730-1ca7-40d4-ec9e-129c3941d138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 269MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip '/content/package detection conveyer belt.v2i.yolov8.zip' -d '/content/data' # Unzipping the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LL63adYnlbL",
        "outputId": "bdc2b50b-4eaf-432d-9c53-ee4d6dd8605f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/package detection conveyer belt.v2i.yolov8.zip\n",
            " extracting: /content/data/README.dataset.txt  \n",
            " extracting: /content/data/README.roboflow.txt  \n",
            " extracting: /content/data/data.yaml  \n",
            "   creating: /content/data/test/\n",
            "   creating: /content/data/test/images/\n",
            " extracting: /content/data/test/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0003_jpg.rf.02ee41a844b0208d524ea8485857816e.jpg  \n",
            " extracting: /content/data/test/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0006_jpg.rf.7b85eba99ead88399626d2e478fbd9b9.jpg  \n",
            "   creating: /content/data/test/labels/\n",
            " extracting: /content/data/test/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0003_jpg.rf.02ee41a844b0208d524ea8485857816e.txt  \n",
            " extracting: /content/data/test/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0006_jpg.rf.7b85eba99ead88399626d2e478fbd9b9.txt  \n",
            "   creating: /content/data/train/\n",
            "   creating: /content/data/train/images/\n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0000_jpg.rf.9b0e695245d243f7da3f65c5827d9a3a.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0000_jpg.rf.c638ff93c2b5659ba0f8e2f890d8f870.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.0b22afdc9aebe28a4c0a6ed051c31c40.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.af828b42f9e2716a2e952a722f669ae0.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.e12ceb0c529e53c8ed3724d9d01bdfc3.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.36b470a8e458572c99b03d3f2416671a.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.437d6c5f45c81e2ac3abbad303aefd05.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.67f550ecbc92a11958a7d8e3b032ca2a.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.1d08c3905e9f3ea43b862a34f6e98591.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.96bf93d5ca8148272838750626be115c.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.a9277b36fc83fad96be5aa70940a77f2.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.498c6e36fa8487b945418b804b777c24.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.5086196a43a53b3cb1ff811bc920d1b2.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.6e2ac03a3c2ca565ff192c837e13aeff.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.aaa39db6f429872e8d8e6a4c6b30ae9c.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.b0984e1db94088fb4e05340ad7df6ece.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.cfe86c6f17d5c99c93934d5fdd4d6b53.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.41b0274b97db317f753f0c3ef4d305d5.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.7e58ebdb9d6484d346c9ffd88c3964fc.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.b555771386c241302eaf988802e9e894.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.014382ff5ad2b7059780e2582d219917.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.037f759aa53a763a68c85daaff54ac85.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.4b6d509cbc2304faa602c86677fa3f1c.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0010_jpg.rf.05d4d40504eb61a2d64ccf5ef4180727.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0010_jpg.rf.a207f87339fc980438d0efbc8ee05be7.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.2aa0527666675a5dcbe87b6eb5d96a9b.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.4f4a657a1ed1476e615d16031460c8ef.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.915dd8931b49df0534bc6530f320d8b7.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.93b4cd0163ae21c82c5acd820c65e8b3.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.d1159d6f58151d6f922fa311d6c4c8e0.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.e674462d6a5b30b51a6ac4d170344ca9.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.3b5461d930d22504f83daefa8544d74b.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.7b8bcb42318c70860920aeb25bb4771f.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.d9abab4716210f44565f2502dabb06ad.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0015_jpg.rf.24a89b4d288ae6abaf98d22cb3e2f338.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0015_jpg.rf.763ec5c9af7cb54cef0f3e9f118d46ee.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.0cdb3c00b87fd739335e5e53aa861907.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.406cdcc98afa00830e4b2f7564ea03f2.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.e16c3856cddfc7f80af08da71f3133a5.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.03eda077016269fcc156d0b7368ab66e.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.b1465f10977c114bc4b170a56c87959d.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.d0572dec81e48b236cd38190e4a65f77.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.3c8c3fddf9c6c0a80d7cc4fb0fa94eed.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.7eb289c4a0900ec37f526d0fc0a6be94.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.8d2bbb5a27b73a6ec2b4b281f4beb0de.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0019_jpg.rf.183d5d3985d69fca321e8670947b21af.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0019_jpg.rf.2cc05d2ffa1695d6234aabf231ee9028.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.d6a71f2ba5a9761632c3323f5bca34ba.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.d9ce5766ff6d39e14558bccc7f36c2a3.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.e47e0fb58490739bf60fe84d547eb840.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.00f126a93f414b29838482c13a3e918d.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.7c13d95c3f39152deb8288bef8e83a13.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.b4f77dc620e13c47bb90613299307485.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.135e81c2ad7c5c5bc7944f47b0e326da.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.308b8f7ef89497ed36b6ec5973831229.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.812ae8f92652704cc8f4152d5ea682af.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0023_jpg.rf.cd74fdf6b64235348d7d9dc0094a3613.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0023_jpg.rf.eded97fccc9940923c388054ae2e5d54.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.0ac9747c73043ead11741edc61d39bfb.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.18f3ebf29531b2e58274d2cf86306a5c.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.37ad88659183316b2ddc2817ff6be2a4.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.033c3eb6066f458c0a0b2c471372b028.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.646d6d1707e30255f11f59dec2ff8002.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.c6d834fbef0179ab96ede3b28a1b9277.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0026_jpg.rf.77982c32a41d5d333190826553c7a120.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0026_jpg.rf.d1d1af8d0024e7388d01f2deb122d836.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.25bfe6dcde98d8645cfe678be09c3962.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.7a42572fa39779dad63d8b737570e2e5.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.f2c6632b2d56af36c98b47edc775a79f.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.20b7277f9efe1460deb1b792ec8c3175.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.a8a06295daf78bc821f0371c01cd61eb.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.f61a09a6a2e3b5d33a4ea3f4fe334cbf.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.7c338ac08a3478ee8233de49ee3553db.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.b035ad9c498c1585bb1e0c07319fcf92.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.d92f24ab1373decc9273e76c4af5dceb.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.405ad1bc6aeb110e4aca1f7568c70363.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.e4fda5b77ad6cd121f2027c6f51a4f28.jpg  \n",
            " extracting: /content/data/train/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.f251f33cfab9ed3db9eb30ca76c81745.jpg  \n",
            "   creating: /content/data/train/labels/\n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0000_jpg.rf.9b0e695245d243f7da3f65c5827d9a3a.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0000_jpg.rf.c638ff93c2b5659ba0f8e2f890d8f870.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.0b22afdc9aebe28a4c0a6ed051c31c40.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.af828b42f9e2716a2e952a722f669ae0.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0001_jpg.rf.e12ceb0c529e53c8ed3724d9d01bdfc3.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.36b470a8e458572c99b03d3f2416671a.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.437d6c5f45c81e2ac3abbad303aefd05.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0002_jpg.rf.67f550ecbc92a11958a7d8e3b032ca2a.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.1d08c3905e9f3ea43b862a34f6e98591.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.96bf93d5ca8148272838750626be115c.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0004_jpg.rf.a9277b36fc83fad96be5aa70940a77f2.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.498c6e36fa8487b945418b804b777c24.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.5086196a43a53b3cb1ff811bc920d1b2.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0005_jpg.rf.6e2ac03a3c2ca565ff192c837e13aeff.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.aaa39db6f429872e8d8e6a4c6b30ae9c.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.b0984e1db94088fb4e05340ad7df6ece.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0007_jpg.rf.cfe86c6f17d5c99c93934d5fdd4d6b53.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.41b0274b97db317f753f0c3ef4d305d5.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.7e58ebdb9d6484d346c9ffd88c3964fc.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0008_jpg.rf.b555771386c241302eaf988802e9e894.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.014382ff5ad2b7059780e2582d219917.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.037f759aa53a763a68c85daaff54ac85.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0009_jpg.rf.4b6d509cbc2304faa602c86677fa3f1c.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0010_jpg.rf.05d4d40504eb61a2d64ccf5ef4180727.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0010_jpg.rf.a207f87339fc980438d0efbc8ee05be7.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.2aa0527666675a5dcbe87b6eb5d96a9b.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.4f4a657a1ed1476e615d16031460c8ef.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0011_jpg.rf.915dd8931b49df0534bc6530f320d8b7.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.93b4cd0163ae21c82c5acd820c65e8b3.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.d1159d6f58151d6f922fa311d6c4c8e0.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0013_jpg.rf.e674462d6a5b30b51a6ac4d170344ca9.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.3b5461d930d22504f83daefa8544d74b.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.7b8bcb42318c70860920aeb25bb4771f.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0014_jpg.rf.d9abab4716210f44565f2502dabb06ad.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0015_jpg.rf.24a89b4d288ae6abaf98d22cb3e2f338.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0015_jpg.rf.763ec5c9af7cb54cef0f3e9f118d46ee.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.0cdb3c00b87fd739335e5e53aa861907.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.406cdcc98afa00830e4b2f7564ea03f2.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0016_jpg.rf.e16c3856cddfc7f80af08da71f3133a5.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.03eda077016269fcc156d0b7368ab66e.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.b1465f10977c114bc4b170a56c87959d.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0017_jpg.rf.d0572dec81e48b236cd38190e4a65f77.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.3c8c3fddf9c6c0a80d7cc4fb0fa94eed.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.7eb289c4a0900ec37f526d0fc0a6be94.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0018_jpg.rf.8d2bbb5a27b73a6ec2b4b281f4beb0de.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0019_jpg.rf.183d5d3985d69fca321e8670947b21af.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0019_jpg.rf.2cc05d2ffa1695d6234aabf231ee9028.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.d6a71f2ba5a9761632c3323f5bca34ba.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.d9ce5766ff6d39e14558bccc7f36c2a3.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0020_jpg.rf.e47e0fb58490739bf60fe84d547eb840.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.00f126a93f414b29838482c13a3e918d.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.7c13d95c3f39152deb8288bef8e83a13.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0021_jpg.rf.b4f77dc620e13c47bb90613299307485.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.135e81c2ad7c5c5bc7944f47b0e326da.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.308b8f7ef89497ed36b6ec5973831229.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0022_jpg.rf.812ae8f92652704cc8f4152d5ea682af.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0023_jpg.rf.cd74fdf6b64235348d7d9dc0094a3613.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0023_jpg.rf.eded97fccc9940923c388054ae2e5d54.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.0ac9747c73043ead11741edc61d39bfb.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.18f3ebf29531b2e58274d2cf86306a5c.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0024_jpg.rf.37ad88659183316b2ddc2817ff6be2a4.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.033c3eb6066f458c0a0b2c471372b028.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.646d6d1707e30255f11f59dec2ff8002.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0025_jpg.rf.c6d834fbef0179ab96ede3b28a1b9277.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0026_jpg.rf.77982c32a41d5d333190826553c7a120.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0026_jpg.rf.d1d1af8d0024e7388d01f2deb122d836.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.25bfe6dcde98d8645cfe678be09c3962.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.7a42572fa39779dad63d8b737570e2e5.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0027_jpg.rf.f2c6632b2d56af36c98b47edc775a79f.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.20b7277f9efe1460deb1b792ec8c3175.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.a8a06295daf78bc821f0371c01cd61eb.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0028_jpg.rf.f61a09a6a2e3b5d33a4ea3f4fe334cbf.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.7c338ac08a3478ee8233de49ee3553db.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.b035ad9c498c1585bb1e0c07319fcf92.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0029_jpg.rf.d92f24ab1373decc9273e76c4af5dceb.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.405ad1bc6aeb110e4aca1f7568c70363.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.e4fda5b77ad6cd121f2027c6f51a4f28.txt  \n",
            " extracting: /content/data/train/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0030_jpg.rf.f251f33cfab9ed3db9eb30ca76c81745.txt  \n",
            "   creating: /content/data/valid/\n",
            "   creating: /content/data/valid/images/\n",
            " extracting: /content/data/valid/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0012_jpg.rf.32037daa1aaca670af99bb09a86e2559.jpg  \n",
            "   creating: /content/data/valid/labels/\n",
            " extracting: /content/data/valid/labels/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0012_jpg.rf.32037daa1aaca670af99bb09a86e2559.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model for 100 epochs , keeping the image size at 640"
      ],
      "metadata": {
        "id": "M_dcksUfNJp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.train(data='/content/data/data.yaml',epochs=100,imgsz=640)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3JmV-RhrQis",
        "outputId": "d06c6e3e-0344-4c52-f36f-e2602a9adf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.45 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/labels... 78 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:00<00:00, 1263.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/valid/labels... 1 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 5041.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100       2.6G       1.42       3.64      1.116        277        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16     0.0267        0.5      0.023      0.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      2.46G      1.277      3.173      1.031        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16     0.0467      0.875     0.0706     0.0457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      2.45G      1.281      2.075     0.9572        297        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16     0.0532      0.875      0.687      0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      2.41G      1.164      1.232     0.9313        345        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.285      0.756      0.481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      2.35G      1.133        1.1     0.9357        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.548      0.819      0.553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      2.46G      1.112      1.011     0.9384        306        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.854      0.368      0.696        0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      2.39G      1.083     0.9775     0.9355        264        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.712      0.464      0.605      0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      2.44G       1.12     0.9084     0.9246        290        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.908      0.619      0.834      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      2.46G      1.068     0.8412     0.9183        289        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.923      0.746      0.771      0.585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      2.29G      1.012     0.8628     0.9429        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.821      0.562      0.722      0.561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      2.42G      1.119     0.8274     0.9322        344        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.865      0.562      0.812      0.552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100       2.4G      1.047     0.8499     0.9487        220        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.905      0.594      0.774      0.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      2.39G      1.058     0.8154     0.9357        400        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.908      0.619      0.766      0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      2.34G      1.083     0.8159     0.9309        289        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.918      0.696      0.777       0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      2.35G      1.065     0.7951     0.9318        247        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.924      0.765      0.839      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      2.45G      1.049     0.7494     0.9368        236        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.849      0.888      0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      2.38G      1.004     0.7623     0.9165        298        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.927      0.793      0.869      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      2.41G      1.045     0.7909     0.9346        209        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.872      0.952      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      2.38G      1.012     0.7569     0.9257        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.906      0.812       0.93      0.686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100       2.5G      1.013     0.7297     0.9262        288        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.848      0.812      0.823       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      2.36G       1.06     0.7386     0.9252        315        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.858      0.812      0.883      0.607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      2.43G      1.006     0.7251      0.917        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.873      0.861      0.922      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      2.32G     0.9951     0.7243     0.9155        316        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.936      0.922      0.976      0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      2.42G     0.9809     0.7218     0.8962        359        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.932      0.855      0.934      0.604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      2.43G     0.9897     0.7063     0.9079        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.921      0.812      0.923      0.662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      2.35G     0.9861     0.7022     0.9118        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.993      0.875      0.985      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      2.34G      1.023     0.6995     0.9231        242        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.937      0.935      0.973      0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      2.33G     0.9925     0.6928     0.9167        276        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16       0.94      0.975      0.984      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      2.32G     0.9475     0.6601     0.9048        303        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16       0.93      0.938      0.982      0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      2.47G     0.9818     0.6784     0.8961        332        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.932      0.991      0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      2.45G     0.9348     0.6765     0.9138        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.931      0.991      0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      2.34G     0.9604     0.6721     0.9085        321        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.924      0.983       0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      2.36G     0.9137     0.6503     0.8996        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.931      0.986      0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      2.46G     0.9517     0.6433      0.887        309        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.934      0.988      0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      2.46G     0.9865     0.6648     0.9022        377        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.998      0.938      0.988      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      2.42G     0.9843      0.651     0.9031        237        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.932      0.983      0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      2.36G     0.9525     0.6452     0.8999        365        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.937      0.935      0.978      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      2.36G     0.9317     0.6249     0.8941        327        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.936      0.916      0.976      0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      2.41G     0.9251     0.6205     0.9091        173        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.946      0.812      0.965      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      2.34G      0.918     0.6085        0.9        303        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16       0.98      0.812      0.969      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      2.42G     0.9158     0.6132     0.9005        326        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.834      0.938      0.971      0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      2.47G     0.9448     0.6257     0.8917        306        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.884      0.956      0.981      0.766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      2.45G     0.9065     0.6055     0.9033        267        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.937      0.931      0.969      0.782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      2.31G     0.9369     0.6145     0.8932        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.926          1      0.984      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      2.35G     0.9149       0.59     0.8804        262        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.931      0.991      0.773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      2.37G     0.8799     0.5929     0.8927        242        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.875          1      0.973      0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      2.34G     0.9104     0.6047     0.9028        295        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.875          1      0.969      0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      2.41G     0.9074     0.5965     0.8987        269        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.927          1      0.973       0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      2.43G     0.9278     0.5972      0.898        277        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.931          1      0.988      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      2.45G     0.9102     0.5804     0.8834        255        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.929          1      0.977      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      2.31G     0.8812     0.5725     0.8842        247        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.939          1      0.966      0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      2.37G     0.9263     0.5931     0.8902        350        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.886      0.976      0.973      0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100       2.4G     0.8962     0.5945      0.894        279        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.886      0.976      0.982      0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      2.46G     0.8784     0.5706      0.887        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      2.43G     0.8618     0.5504     0.8805        271        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.997      0.995      0.751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      2.44G     0.9001     0.5492     0.8772        312        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.992      0.995      0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      2.29G     0.8972     0.5818     0.8912        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.996      0.938      0.991      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      2.28G     0.8796     0.5693     0.8942        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.996      0.938      0.991      0.699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      2.44G     0.9094     0.5719     0.8903        245        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.995      0.938      0.988      0.717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      2.35G     0.8852     0.5657     0.8802        283        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.995      0.938      0.988      0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100      2.43G     0.8917     0.5603     0.8768        316        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.996      0.938      0.991      0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      2.46G     0.8475     0.5353     0.8812        287        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.993      0.995       0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      2.38G     0.8544     0.5408     0.8779        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      2.35G     0.8338     0.5306     0.8728        232        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.994      0.995      0.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      2.34G     0.8639      0.534     0.8713        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.994      0.995      0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      2.41G     0.8514     0.5293      0.872        318        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      2.37G     0.8411     0.5323     0.8764        346        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.996      0.995      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      2.38G     0.8575     0.5327     0.8742        333        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      2.42G     0.8461     0.5286     0.8664        267        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      2.43G     0.8146     0.5201     0.8742        225        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      2.43G     0.8348     0.5294     0.8704        234        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.994      0.995      0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      2.39G     0.8281     0.5197     0.8739        292        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.995      0.938      0.991      0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      2.46G     0.8277     0.5112     0.8613        332        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.995      0.938      0.991      0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      2.41G     0.8267     0.5162     0.8784        234        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995      0.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      2.43G     0.8076     0.5151     0.8725        276        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995       0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      2.39G     0.8373      0.524     0.8768        313        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.995      0.995       0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      2.44G     0.8277     0.5129     0.8633        351        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.941      0.994      0.991      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      2.36G     0.7975     0.5066     0.8742        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.888      0.993      0.988      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      2.33G     0.7927     0.5182     0.8661        293        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.888      0.992      0.981      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      2.42G     0.7906     0.4988     0.8676        259        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.933      0.867       0.96       0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100       2.4G     0.8107     0.5062     0.8672        315        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1       0.93      0.988        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      2.44G     0.7946      0.496     0.8625        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.928      0.988      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      2.42G     0.8118     0.4951     0.8751        209        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.925      0.986      0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      2.34G     0.7804     0.4908     0.8627        272        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.929      0.938      0.978      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      2.36G     0.8036     0.5011     0.8581        333        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.931      0.938      0.978      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      2.33G     0.8024     0.4902     0.8648        313        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.983      0.938      0.986      0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      2.37G     0.7858     0.4942     0.8666        256        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.969      0.938      0.988       0.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      2.35G     0.8301     0.5028     0.8691        394        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.968      0.938      0.988      0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      2.43G      0.792      0.491     0.8623        331        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.986      0.938      0.988      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      2.37G     0.7864      0.486     0.8571        317        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.984      0.938      0.988      0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      2.49G     0.7758     0.5039     0.8728        184        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16       0.99      0.938      0.988      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100      2.21G      0.761     0.4963     0.8635        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.934      0.938      0.988      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      2.33G     0.7282     0.4816     0.8589        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.888          1      0.988      0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      2.23G     0.7546     0.4982     0.8677        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.941          1      0.991      0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      2.22G     0.7288     0.4723     0.8514        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.941          1      0.991      0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      2.22G     0.7579     0.4823     0.8634        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.941      0.999      0.991      0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      2.22G     0.7084     0.4589     0.8559        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.889      0.999      0.988      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      2.23G     0.7123     0.4569      0.865        181        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.888          1      0.988      0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100      2.22G     0.7333     0.4676      0.855        195        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.997      0.995      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      2.22G     0.7226      0.463     0.8606        162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16          1      0.998      0.995      0.758\n",
            "\n",
            "100 epochs completed in 0.062 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.45 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1         16      0.937      0.931      0.969      0.782\n",
            "Speed: 0.4ms preprocess, 17.6ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions through fine tuned model\n"
      ],
      "metadata": {
        "id": "r8hi970sNVPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict('/content/data/valid/images/6d29e184479eef3ae9899bb8101069d7-720p-preview-1-_mp4-0012_jpg.rf.32037daa1aaca670af99bb09a86e2559.jpg',save=True)"
      ],
      "metadata": {
        "id": "v7eGoEpOKDRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict('/content/original logistic package video.mp4',save=True)"
      ],
      "metadata": {
        "id": "6evSFbj1N3E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### saving the fine tuned yolov8 model"
      ],
      "metadata": {
        "id": "Rpn6L4CuH0P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(format='onnx') # if you won't give format here then model will be saved in pytorch format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Yg3KZ1yQH4xI",
        "outputId": "3e91fc03-774a-43cb-eef1-46b5cd951928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.45 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.9/15.9 MB 185.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 11.1s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 12.0s, saved as 'runs/detect/train/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (13.5s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=/content/data/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'runs/detect/train/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the saved model and checking it"
      ],
      "metadata": {
        "id": "Q1-G3IIpKVlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "loaded_model=YOLO('/content/drive/MyDrive/package detector conveyer belt model/best.pt')\n",
        "loaded_model.model.names"
      ],
      "metadata": {
        "id": "ZTVPZY5KJcbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510540b8-1ec3-4352-f890-990449e62c02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'parcel'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH='/content/drive/MyDrive/package detector conveyer belt model/original logistic package video.mp4'"
      ],
      "metadata": {
        "id": "GncG7OEl13g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will detect count and track packages in whole video"
      ],
      "metadata": {
        "id": "cKv6gsf4I7d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the line coordinates"
      ],
      "metadata": {
        "id": "Ndu6Ng_JP7Ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can create end and start points for line on the video using\n",
        "* https://roboflow.github.io/polygonzone/\n",
        "* just upload your frame or image from the video here and draw the line to get the coordinates"
      ],
      "metadata": {
        "id": "y6QSlQhvnW7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Code"
      ],
      "metadata": {
        "id": "JS66ldXYEbud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using yolov8 own tracking bytetrack on default it uses botsort for tracking"
      ],
      "metadata": {
        "id": "cp-IlU-JSlYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3nJtWUyECJx",
        "outputId": "d0b3039b-2c76-49b4-e77e-8a1fa3dace16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.27-py3-none-any.whl (779 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BcavvcWDVkg",
        "outputId": "c641f3e6-f6d0-419a-827d-60707de58e20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.20.0-py3-none-any.whl (110 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/111.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.9.0.80)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Installing collected packages: supervision\n",
            "Successfully installed supervision-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from collections import defaultdict\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/drive/MyDrive/package detector conveyer belt model/best.pt')\n",
        "\n",
        "# Set up video capture\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/package detector conveyer belt model/original logistic package video.mp4\")\n",
        "\n",
        "# Define the line coordinates\n",
        "START1 =sv.Point(116,492) # Horizontal line on the left\n",
        "END1 =sv.Point(466,492)\n",
        "\n",
        "START2 = sv.Point(1182, 237) # vertical line on right\n",
        "END2 = sv.Point(1184, 470)\n",
        "\n",
        "START3 = sv.Point(561,582) # Horizontal line on middle\n",
        "END3 = sv.Point(665,582)\n",
        "\n",
        "\n",
        "\n",
        "# Create dictionaries to keep track of objects that have crossed the lines\n",
        "crossed_objects = {}\n",
        "crossed_objects_line2 = {}\n",
        "crossed_objects_line3 = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Open a video sink for the output video\n",
        "video_info =sv.VideoInfo.from_video_path(\"/content/drive/MyDrive/package detector conveyer belt model/original logistic package video.mp4\")\n",
        "with sv.VideoSink(\"output_package_counter_video.mp4\", video_info) as sink:\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "\n",
        "        if success:\n",
        "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "            results = model.track(frame, persist=True, save=True, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "            # Get the boxes and track IDs\n",
        "            boxes = results[0].boxes.xywh.cpu()\n",
        "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "\n",
        "            # Visualize the results on the frame\n",
        "            annotated_frame = results[0].plot()\n",
        "\n",
        "\n",
        "\n",
        "            # Plot the tracks and count objects crossing the lines\n",
        "            for box, track_id in zip(boxes, track_ids):\n",
        "                x, y, w, h = box\n",
        "\n",
        "\n",
        "                # Check if the object crosses each line\n",
        "\n",
        "                if START1.x < x < END1.x and y > START1.y: #Done\n",
        "                     if track_id not in crossed_objects:\n",
        "                        crossed_objects[track_id] = True\n",
        "\n",
        "                if START2.y < y < END2.y and abs(x - START2.x) < 5: # Done\n",
        "                     if track_id not in crossed_objects_line2:\n",
        "                        crossed_objects_line2[track_id] = True\n",
        "\n",
        "\n",
        "                if START3.x < x < END3.x and abs(y-START3.y) < 15: # Done\n",
        "                    if track_id not in crossed_objects_line3:\n",
        "                        crossed_objects_line3[track_id] = True\n",
        "\n",
        "                cv2.rectangle(annotated_frame, (int(x - w / 2), int(y - h / 2)),\n",
        "                              (int(x + w / 2), int(y + h / 2)), (0, 255, 0), 2)\n",
        "\n",
        "            # Draw the lines on the frame\n",
        "            cv2.line(annotated_frame, (START1.x, START1.y), (END1.x, END1.y), (0, 255, 0), 2)\n",
        "            cv2.line(annotated_frame, (START2.x, START2.y), (END2.x, END2.y), (0, 255, 0), 2)\n",
        "            cv2.line(annotated_frame, (START3.x, START3.y), (END3.x, END3.y), (0, 255, 0), 2)\n",
        "\n",
        "            # Write the count of objects on each frame\n",
        "            count_text = f\"Objects crossed longest horizontal line on left: {len(crossed_objects)}\"\n",
        "            cv2.putText(annotated_frame, count_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            count_text_2 = f\"Objects crossed  vertical line on the right exit : {len(crossed_objects_line2)}\"\n",
        "            cv2.putText(annotated_frame, count_text_2, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            count_text_3 = f\"Objects crossed horizontal line Entry in the middle: {len(crossed_objects_line3)}\"\n",
        "            cv2.putText(annotated_frame, count_text_3, (10,90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            # Write the frame with annotations to the output video\n",
        "            sink.write_frame(annotated_frame)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYcvDOLoCoEQ",
        "outputId": "f6519d25-4451-406c-a885-0b8b164efd6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n",
            "Collecting lapx>=0.5.2\n",
            "  Downloading lapx-0.5.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 38.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.25.2)\n",
            "Installing collected packages: lapx\n",
            "Successfully installed lapx-0.5.9\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 9.4s, installed 1 package: ['lapx>=0.5.2']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "0: 384x640 14 parcels, 240.4ms\n",
            "Speed: 15.5ms preprocess, 240.4ms inference, 3848.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.9ms\n",
            "Speed: 4.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.7ms\n",
            "Speed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 13.3ms\n",
            "Speed: 4.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.9ms\n",
            "Speed: 5.7ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.6ms\n",
            "Speed: 3.8ms preprocess, 8.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 20.4ms\n",
            "Speed: 4.0ms preprocess, 20.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 15.6ms\n",
            "Speed: 4.2ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.0ms\n",
            "Speed: 1.6ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.0ms\n",
            "Speed: 2.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 6.8ms\n",
            "Speed: 2.4ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.0ms\n",
            "Speed: 2.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.2ms\n",
            "Speed: 2.4ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.0ms\n",
            "Speed: 4.1ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.2ms\n",
            "Speed: 1.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.0ms\n",
            "Speed: 2.6ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.0ms\n",
            "Speed: 2.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.8ms\n",
            "Speed: 2.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.5ms\n",
            "Speed: 3.6ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.9ms\n",
            "Speed: 3.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.8ms\n",
            "Speed: 2.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.4ms\n",
            "Speed: 2.4ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 6.8ms\n",
            "Speed: 2.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.4ms\n",
            "Speed: 2.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.4ms\n",
            "Speed: 2.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.5ms\n",
            "Speed: 2.4ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.7ms\n",
            "Speed: 3.3ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.6ms\n",
            "Speed: 3.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.3ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 12.3ms\n",
            "Speed: 4.1ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 10.1ms\n",
            "Speed: 3.8ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 13.6ms\n",
            "Speed: 3.3ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.7ms\n",
            "Speed: 4.5ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 11.8ms\n",
            "Speed: 7.0ms preprocess, 11.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 20.3ms\n",
            "Speed: 1.9ms preprocess, 20.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 13.5ms\n",
            "Speed: 4.6ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.7ms\n",
            "Speed: 1.7ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.5ms\n",
            "Speed: 1.7ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.5ms\n",
            "Speed: 1.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 6.7ms\n",
            "Speed: 2.3ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 3.7ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.6ms\n",
            "Speed: 4.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.1ms\n",
            "Speed: 1.7ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.1ms\n",
            "Speed: 3.4ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.5ms\n",
            "Speed: 5.6ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.4ms\n",
            "Speed: 3.4ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 7.5ms\n",
            "Speed: 3.4ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.0ms\n",
            "Speed: 3.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 7.3ms\n",
            "Speed: 2.5ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 6.5ms\n",
            "Speed: 3.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 6.6ms\n",
            "Speed: 3.0ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.9ms\n",
            "Speed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.0ms\n",
            "Speed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.9ms\n",
            "Speed: 4.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.6ms\n",
            "Speed: 5.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 13.1ms\n",
            "Speed: 4.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 5.5ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 14.5ms\n",
            "Speed: 3.8ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.7ms\n",
            "Speed: 2.4ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.3ms\n",
            "Speed: 4.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 6.6ms\n",
            "Speed: 2.5ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 8 parcels, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 7 parcels, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.8ms\n",
            "Speed: 3.9ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 6.8ms\n",
            "Speed: 4.1ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 9 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 5.6ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 14.6ms\n",
            "Speed: 1.7ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.8ms\n",
            "Speed: 4.1ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.5ms\n",
            "Speed: 1.7ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 18 parcels, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 18 parcels, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 19 parcels, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 7.4ms\n",
            "Speed: 2.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 17 parcels, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 6.8ms\n",
            "Speed: 2.9ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 16 parcels, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 15 parcels, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.1ms\n",
            "Speed: 2.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 14 parcels, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 7.8ms\n",
            "Speed: 2.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.8ms\n",
            "Speed: 4.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.6ms\n",
            "Speed: 2.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 7.4ms\n",
            "Speed: 2.2ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.8ms\n",
            "Speed: 6.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 12.9ms\n",
            "Speed: 1.7ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 10 parcels, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 18.3ms\n",
            "Speed: 1.9ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.4ms\n",
            "Speed: 2.7ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 13 parcels, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 12 parcels, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "\n",
            "0: 384x640 11 parcels, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVU16w05H7mF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}